{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align:right\"> Student: Antoine Moulin </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD-TSIA 214\n",
    "# Computer Lab: Sentiment analysis in textual movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Lab's authors:</b> Chloé Clavel, Laurence Likforman, Emile Chapuis, Hamid Jalalzai <br/>\n",
    "<b>Date:</b> June 5, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import re, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading dataset\")\n",
    "\n",
    "from glob import glob\n",
    "filenames_neg = sorted(glob(op.join('./', 'data', 'imdb1', 'neg', '*.txt')))\n",
    "filenames_pos = sorted(glob(op.join('./', 'data', 'imdb1', 'pos', '*.txt')))\n",
    "\n",
    "texts_neg = [open(f).read() for f in filenames_neg]\n",
    "texts_pos = [open(f).read() for f in filenames_pos]\n",
    "texts = texts_neg + texts_pos\n",
    "y = np.ones(len(texts), dtype=np.int)\n",
    "y[:len(texts_neg)] = 0.\n",
    "\n",
    "print(\"%d documents\" % len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "<b>Complete the <tt>count_words</tt> function that will count the number of occurrences of each distinct word in a list of <tt>string</tt> and return <tt>vocabulary</tt> (the Python dictionary) and <tt>counts</tt>. Do no forget to delete the punctuation. Give the vocabulary size.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(texts):\n",
    "    \"\"\"Vectorize text: return count of each word in the text snippets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts: list of str\n",
    "        The texts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary: dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "    counts: ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialization\n",
    "    table = str.maketrans('', '', string.punctuation) # to remove punctuation\n",
    "    words = set()\n",
    "    vocabulary = dict()\n",
    "    \n",
    "    # build the dictionary\n",
    "    cleaned_texts = []\n",
    "    index = 0\n",
    "    \n",
    "    for text in texts:\n",
    "        text = text.translate(table).lower().replace('\\n', '').split() # removes punctuation \n",
    "        cleaned_texts.append(text) # just to be faster when building counts (avoid a second pre-processing)\n",
    "        for word in text:\n",
    "            if word not in words: # to make sure every word is added only once to the dictionary\n",
    "                vocabulary[word] = index\n",
    "                index += 1\n",
    "                words.add(word)\n",
    "                \n",
    "    # build counts\n",
    "    n_features = len(words)\n",
    "    counts = np.zeros((len(texts), n_features))\n",
    "    \n",
    "    for k in range(len(cleaned_texts)):\n",
    "        text = cleaned_texts[k]\n",
    "        for word in list(set(text)):\n",
    "            counts[k, vocabulary[word]] = text.count(word)\n",
    "    \n",
    "    return vocabulary, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary, counts = count_words(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the vocabulary is: 47567\n"
     ]
    }
   ],
   "source": [
    "print('The size of the vocabulary is: {}'.format(counts.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "<b>Explain how positive and negative classes have been assigned to movie reviews (see <tt>poldata.README.2.0</tt> file).</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the file, <b>the assignement of the class is based on the rating that appears in the review</b>. It may take different forms: five-star system, four-star system, letter grade system. And to classify a review as a positive example or a negative one, they use arbitrary rules such as: \n",
    "\n",
    "\"With a five-star system, three-and-a-half stars and up are considered positive, two stars and below are considered negative.\"\n",
    "\n",
    "In this case, it is not explained how they classify reviews whose rating is between two stars and three-and-a-half stars. One may think they do not take a review into account if it has a rating in this interval in order to minimize their errors during the creation of the ground truth labels.\n",
    "\n",
    "\n",
    "Half stars are difficult to recognize so they may lose a half star occasionally, but this was a minor issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "<b>Complete the <tt>NB</tt> class to implement the Naive Bayes classifier by relying on the pseudo-code of Figure 1 and its documentation below:\n",
    "\n",
    "- The vocabulary $V$ corresponds to the set of different words composing a set of documents (<tt>vocabulary</tt> in <tt>count_words</tt>).\n",
    "- $\\mathbb{C}$ corresponds to all classes and $\\mathbb{D}$ to the set of documents.\n",
    "- The function <tt>countTokensOfTerm(text, t)</tt> represents the number of occurrences of a word <tt>t</tt> in a set of texts <tt>texts</tt> (calculation done in <tt>count_words</tt>).\n",
    "- The smoothing step called Laplace smoothing (+1 line 10) allows the attribution of non-zero probability to words that would not occur in the learning set.\n",
    "- The function <tt>ExtractTokensFromDoc(V, d)</tt> retrieves the list of associated words (including the duplicates) to document <tt>d</tt>.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes classifier uses the maximum a posteriori as a decision rule. Given an observation $o$, it predicts the class $\\widehat{c}$ that maximizes the probability a posteriori, i.e.\n",
    "\n",
    "$$ \\widehat{c} = \\underset{c \\in \\mathbb{C}}{\\arg \\max} \\, \\mathbb{P} \\left( c | o \\right) $$\n",
    "\n",
    "Using the Bayes rule and the independance of $o$ and $c$,\n",
    "\n",
    "$$ \\widehat{c} = \\underset{c \\in \\mathbb{C}}{\\arg \\max} \\, \\frac{\\mathbb{P} \\left( o | c \\right) \\mathbb{P} \\left( c \\right)}{\\mathbb{P} \\left(o \\right)} = \\underset{c \\in \\mathbb{C}}{\\arg \\max} \\, \\mathbb{P} \\left( o | c \\right) \\mathbb{P} \\left( c \\right)$$\n",
    "\n",
    "When implementing a Naive Bayes classifier, the goal is thus to compute these two last terms, $\\mathbb{P} \\left( o | c \\right)$ and $\\mathbb{P} \\left( c \\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class NB(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit our model to the data set (X, y)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray, shape (n_samples, vocabulary_size)\n",
    "            The vectorized training set.\n",
    "            n_samples == number of documents.\n",
    "            vocabulary_size == number of words in vocabulary.\n",
    "            \n",
    "        y: ndarray, shape (n_samples,)\n",
    "            The class of each document (0: negative, 1: positive).\n",
    "            n_samples == number of documents.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self: NB\n",
    "            The Naive Bayes model trained on (X, y).\n",
    "        \"\"\"\n",
    "\n",
    "        # initialization\n",
    "        N, vocab_size = X.shape # N: number of documents, vocab_size: number of words in vocabulary\n",
    "\n",
    "        self.classes = list(set(y))\n",
    "        self.nb_classes = len(self.classes)\n",
    "\n",
    "        self.prior = np.zeros(self.nb_classes) # distribution of the classes\n",
    "        self.cond_prob = np.zeros((vocab_size, self.nb_classes)) # conditional probabilities\n",
    "\n",
    "        for c in self.classes:\n",
    "            # prior\n",
    "            N_c = sum(y == c)\n",
    "            self.prior[c] = N_c / N\n",
    "\n",
    "            # T_c, no need to concatenate texts from class c\n",
    "            T_c = np.zeros(vocab_size)\n",
    "            for t in range(vocab_size):\n",
    "                T_c[t] = sum(X[(y == c), t]) # count tokens of term t in texts with class c\n",
    "            \n",
    "            # conditional probability\n",
    "            normalize = sum(T_c + 1)\n",
    "            for t in range(vocab_size):\n",
    "                self.cond_prob[t][c] = (T_c[t] + 1) / normalize # Laplace smoothing \n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the classes of documents in X\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: ndarray, shape (n_samples, vocabulary_size)\n",
    "            The vectorized training set.\n",
    "            n_samples == number of documents.\n",
    "            vocabulary_size == number of words in vocabulary.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        predictions: ndarray, shape (n_samples)\n",
    "            The predicted classes.\n",
    "            n_samples == number of documents.\n",
    "        \"\"\"\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        predictions = np.zeros(n_samples, dtype=int)\n",
    "        \n",
    "        for k in range(n_samples):\n",
    "            W = np.argwhere(X[k] != 0).flatten().tolist() # extract tokens from document\n",
    "        \n",
    "            scores = np.zeros(self.nb_classes)\n",
    "            for c in self.classes:\n",
    "                scores[c] = np.log(self.prior[c])\n",
    "                for t in W:\n",
    "                    scores[c] += X[k, t]*np.log(self.cond_prob[t][c])\n",
    "        \n",
    "            predictions[k] = np.argmax(scores)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words in text\n",
    "vocabulary, X = count_words(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is: 0.818\n"
     ]
    }
   ],
   "source": [
    "# Try to fit, predict and score\n",
    "nb = NB()\n",
    "nb.fit(X[::2], y[::2])\n",
    "print('The score is: {}'.format(nb.score(X[1::2], y[1::2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "<b>Evaluate the performance of your classifier in cross-validation 5-folds.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score of Naive Bayes: 0.816 (+/- 0.0246)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(nb, X, y, cv=5)\n",
    "\n",
    "print('CV score of Naive Bayes: {} (+/- {})'.format(round(cv_scores.mean(), 4), \n",
    "                                                    round(cv_scores.std() * 2, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "<b>Change the <tt>count_words</tt> function to ignore the “stop words” in the file <tt>data/english.stop</tt>. Are the performances improved?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(texts, stopwords_path = './data/english.stop'):\n",
    "    \"\"\"Vectorize text: return count of each word in the text snippets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts: list of str\n",
    "        The texts.\n",
    "        \n",
    "    stopwords_path: str\n",
    "        Path to the list of stopwords.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary: dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "        \n",
    "    counts: ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialization\n",
    "    stopwords = open(stopwords_path).read().replace('\\n', ' ').replace('\\'', '').split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    words = set()\n",
    "    vocabulary = dict()\n",
    "    \n",
    "    # build the dictionary\n",
    "    cleaned_texts = []\n",
    "    index = 0\n",
    "    \n",
    "    for text in texts:\n",
    "        text = text.translate(table).lower().replace('\\n', '').split() # removes punctuation\n",
    "        text = [w for w in text if w not in stopwords] # removes stopwords\n",
    "        cleaned_texts.append(text) # just to be faster when building counts (avoid a second pre-processing)\n",
    "        for word in text:\n",
    "            if word not in words: # to make sure every word is added only once in the dictionary\n",
    "                vocabulary[word] = index\n",
    "                index += 1\n",
    "                words.add(word)\n",
    "                \n",
    "    # build counts\n",
    "    n_features = len(words)\n",
    "    counts = np.zeros((len(cleaned_texts), n_features))\n",
    "    \n",
    "    for k in range(len(cleaned_texts)):\n",
    "        text = cleaned_texts[k]\n",
    "        for word in list(set(text)):\n",
    "            counts[k, vocabulary[word]] = text.count(word)\n",
    "    \n",
    "    return vocabulary, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words in text\n",
    "vocabulary, X = count_words(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is: 0.797\n"
     ]
    }
   ],
   "source": [
    "# Try to fit, predict and score\n",
    "nb = NB()\n",
    "nb.fit(X[::2], y[::2])\n",
    "print('The score is: {}'.format(nb.score(X[1::2], y[1::2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score of Naive Bayes without the stopwords: 0.814 (+/- 0.0236)\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(nb, X, y, cv=5)\n",
    "\n",
    "print('CV score of Naive Bayes without the stopwords: {} (+/- {})'.format(round(cv_scores.mean(), 4), \n",
    "                                                                          round(cv_scores.std() * 2, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the performances are a bit improved, but not that much. Besides, the standard deviation is higher. When the model is trained with half of the data set (two cells above), the score is lower than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts, stopwords_path='./data/english.stop'):\n",
    "    \"\"\"Remove the stopwords and the punctuation in a list of texts\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    texts: list of str\n",
    "        The texts.\n",
    "        \n",
    "    stopwords_path: str\n",
    "        Path to the list of stopwords.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    cleaned_texts: list of str\n",
    "        The texts without the stopwords and the punctuation.\n",
    "    \"\"\"\n",
    "    \n",
    "    stopwords = open(stopwords_path).read().replace('\\n', ' ').replace('\\'', '').split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "    cleaned_texts = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = text.translate(table).lower().replace('\\n', '').split() # removes punctuation\n",
    "        text = [w for w in text if w not in stopwords] # removes stopwords\n",
    "        \n",
    "        cleaned_texts.append(' '.join(text))\n",
    "        \n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "<b>Compare your implementation with <tt>scikit-learn</tt>.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will keep the stopwords. Indeed, even if it seemed that it was better without the stopwords in a previous question, a few tests showed that the performances are better if we keep the stopwords (at least when we allow n-grams or when we use substrings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Vectorizers for the pre-processing\n",
    "vect = CountVectorizer()\n",
    "vect_bigrams = CountVectorizer(ngram_range=(1, 2))\n",
    "vect_35grams = CountVectorizer(ngram_range=(3, 5))\n",
    "\n",
    "vect_13substrings = CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
    "vect_36substrings = CountVectorizer(analyzer='char', ngram_range=(3, 6))\n",
    "\n",
    "\n",
    "# The model used\n",
    "nb_sklearn = MultinomialNB()\n",
    "\n",
    "\n",
    "# The pipelines\n",
    "nb_bigrams = Pipeline(steps=[('bigrams', vect_bigrams), ('naive Bayes', nb_sklearn)])\n",
    "nb_35grams = Pipeline(steps=[('3-5 grams', vect_35grams), ('naive Bayes', nb_sklearn)])\n",
    "\n",
    "nb_13substrings = Pipeline(steps=[('substrings', vect_13substrings), ('naive Bayes', nb_sklearn)])\n",
    "nb_36substrings = Pipeline(steps=[('substrings', vect_36substrings), ('naive Bayes', nb_sklearn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score of Naive Bayes with bigrams: 0.8305 (+/- 0.0185)\n",
      "CV score of Naive Bayes with 3-5 grams: 0.8135 (+/- 0.0384)\n",
      "CV score of Naive Bayes with substrings (length: 1-3): 0.7475 (+/- 0.0283)\n",
      "CV score of Naive Bayes with substrings (length: 3-6): 0.8215 (+/- 0.0304)\n"
     ]
    }
   ],
   "source": [
    "cv_scores_bigrams = cross_val_score(nb_bigrams, texts, y, cv=5)\n",
    "cv_scores_35grams = cross_val_score(nb_35grams, texts, y, cv=5)\n",
    "\n",
    "cv_scores_13substrings = cross_val_score(nb_13substrings, texts, y, cv=5)\n",
    "cv_scores_36substrings = cross_val_score(nb_36substrings, texts, y, cv=5)\n",
    "\n",
    "print('CV score of Naive Bayes with bigrams: {} (+/- {})'.format(round(cv_scores_bigrams.mean(), 4),\n",
    "                                                                 round(cv_scores_bigrams.std() * 2, 4)))\n",
    "\n",
    "print('CV score of Naive Bayes with 3-5 grams: {} (+/- {})'.format(round(cv_scores_35grams.mean(), 4),\n",
    "                                                                   round(cv_scores_35grams.std() * 2, 4)))\n",
    "\n",
    "print('CV score of Naive Bayes with substrings (length: 1-3): {} (+/- {})'.format(round(cv_scores_13substrings.mean(), 4),\n",
    "                                                                                  round(cv_scores_13substrings.std() * 2, 4)))\n",
    "\n",
    "print('CV score of Naive Bayes with substrings (length: 3-6): {} (+/- {})'.format(round(cv_scores_36substrings.mean(), 4),\n",
    "                                                                                  round(cv_scores_36substrings.std() * 2, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the question $4$, we had an accuracy of $0.826$. Here, we see that only the method allowing bigrams is better. However, it is still a bit lower than the accuracy obtained simply without the stopwords, but the standard deviation is smaller ($0.019$ instead of $0.029$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "<b>Test another classification method <tt>scikit-learn</tt> (e.g. <tt>LinearSVC</tt>, <tt>LogisticRegression</tt>).</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the previous question, allowing bigrams improves the performances, so we do the same with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell takes more than 10 minutes to execute, with results similar to the ones obtained with logistic regression\n",
    "# # so it may be better not to execute it\n",
    "\n",
    "\n",
    "# p_grid_lsvm = {'C': [1e-3, 1e-2, 1e-1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1e1]}\n",
    "\n",
    "# inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # nested CV with parameter optimization\n",
    "# svc = GridSearchCV(estimator=LinearSVC(), param_grid=p_grid_lsvm, cv=inner_cv)\n",
    "# nested_score = cross_val_score(svc, vect.fit_transform(texts), y, cv=outer_cv,scoring=\"accuracy\")\n",
    "\n",
    "# print('Nested CV score of the SVC: {} (+/- {})'.format(round(nested_score.mean(), 4),\n",
    "#                                                        round(nested_score.std() * 2, 4)))\n",
    "\n",
    "# # nested CV with parameter optimization\n",
    "# nested_score_bigrams = cross_val_score(svc, vect_bigrams.fit_transform(texts), y, cv=outer_cv,scoring=\"accuracy\")\n",
    "\n",
    "# print('Nested CV score of the SVC (with bigrams): {} (+/- {})'.format(round(nested_score_bigrams.mean(), 4),\n",
    "#                                                                       round(nested_score_bigrams.std() * 2, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score of the logistic regression: 0.8415 (+/- 0.0336)\n",
      "CV score of the logistic regression (with bigrams): 0.8525 (+/- 0.033)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "lr = Pipeline([('vect', vect), ('logistic_regression', LogisticRegression())])\n",
    "lr.set_params(logistic_regression__solver='liblinear')\n",
    "\n",
    "cv_scores_lr = cross_val_score(lr, texts, y, cv=5)\n",
    "\n",
    "print('CV score of the logistic regression: {} (+/- {})'.format(round(cv_scores_lr.mean(), 4), \n",
    "                                                                round(cv_scores_lr.std() * 2, 4)))\n",
    "\n",
    "\n",
    "# Logistic regression with bigrams\n",
    "lr_bigrams = Pipeline([('bigrams', vect_bigrams), ('logistic_regression', LogisticRegression())])\n",
    "lr_bigrams.set_params(logistic_regression__solver='liblinear')\n",
    "\n",
    "cv_scores_lr_bigrams = cross_val_score(lr_bigrams, texts, y, cv=5)\n",
    "\n",
    "print('CV score of the logistic regression (with bigrams): {} (+/- {})'.format(round(cv_scores_lr_bigrams.mean(), 4), \n",
    "                                                                               round(cv_scores_lr_bigrams.std() * 2, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the results are better than what we had before, and it is the logistic regression with bigrams that has the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "<b>Use NLTK library in order to process a stemming. You will use the class <tt>SnowballStemmer</tt>.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let process a stemming, i.e. we only keep the stem of each word (that has the avantage to give the same representation for a word and its different forms such as the plural)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer\n",
    "\n",
    "def stem_texts(texts):\n",
    "    \"\"\"Apply stemming on a list of texts\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    texts: list of str\n",
    "        The texts\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    stemmed_texts: list of str\n",
    "        The stemmed texts\n",
    "    \"\"\"\n",
    "    \n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "    stemmed_texts = []\n",
    "\n",
    "    for text in texts:\n",
    "        text = text.translate(table).lower().replace('\\n', '').split()\n",
    "        text = [stemmer.stem(w) for w in text]\n",
    "        stemmed_texts.append(' '.join(text))\n",
    "        \n",
    "    return stemmed_texts\n",
    "\n",
    "stemmed_texts = stem_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score of the logistic regression (bigrams, stemming): 0.853 (+/- 0.0287)\n"
     ]
    }
   ],
   "source": [
    "cv_scores_stem_lr = cross_val_score(lr_bigrams, stemmed_texts, y, cv=5)\n",
    "\n",
    "print('CV score of the logistic regression (bigrams, stemming): {} (+/- {})'.format(round(cv_scores_stem_lr.mean(), 4), \n",
    "                                                                                    round(cv_scores_stem_lr.std() * 2, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score obtained is a bit better than with bigrams only. The improvement is not huge but it shows the stemming has a positive impact on the performances, which makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "<b>Filter words by grammatical category (POS: Part Of Speech) and keep only nouns, verbs, adverbs and adjectives for classification.<b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "POS_kept = ['NOUN', 'VERB', 'ADV', 'ADJ']\n",
    "\n",
    "def pos_tagging_texts(texts, keep=POS_kept):\n",
    "    \"\"\"Apply POS tagging selection to a list of texts\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    texts: list of str\n",
    "        The texts\n",
    "    keep: list of str\n",
    "        List of the grammatical categories to keep\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    texts_pos: list of str\n",
    "        The texts in which we only keep some grammatical categories\n",
    "    \"\"\"\n",
    "\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "    texts_pos = []\n",
    "\n",
    "    for text in texts:\n",
    "        text = text.translate(table).lower().replace('\\n', '').split()\n",
    "        text_pos = ''\n",
    "\n",
    "        for word, pos in pos_tag(text, tagset='universal'):\n",
    "            if pos in POS_kept:\n",
    "                text_pos += word + ' '\n",
    "\n",
    "        texts_pos.append(text_pos)\n",
    "        \n",
    "    return texts_pos\n",
    "\n",
    "texts_pos = pos_tagging_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score of the logistic regression (bigrams, pos tagging): 0.8535 (+/- 0.0299)\n"
     ]
    }
   ],
   "source": [
    "cv_scores_lr_pos_tag = cross_val_score(lr_bigrams, texts_pos, y, cv=5)\n",
    "\n",
    "print('CV score of the logistic regression (bigrams, pos tagging): {} (+/- {})'.format(round(cv_scores_lr_pos_tag.mean(), 4), \n",
    "                                                                                    round(cv_scores_lr_pos_tag.std() * 2, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pos tagging is a bit better than the stemming. It is the best result we obtained yet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
